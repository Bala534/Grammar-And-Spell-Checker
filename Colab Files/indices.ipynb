{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "indices.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsK28u-OmAoJ"
      },
      "source": [
        "from collections import OrderedDict\n",
        "import json\n",
        "\n",
        "input_lines = []\n",
        "output_lines = []\n",
        "with open(\"input.txt\") as file_in:\n",
        "  for line in file_in:\n",
        "    input_lines.append(line)\n",
        " \n",
        "with open(\"ABCDN.test.bea19.corr\") as file_in:\n",
        "  for line in file_in:\n",
        "    output_lines.append(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8DzcNxPmF2J"
      },
      "source": [
        "#sample input preparation\n",
        "# sample_input = []\n",
        "# sample_output = []\n",
        "# sample_input.append(input_lines[6])\n",
        "# sample_output.append(output_lines[6])\n",
        "# sample_input.append(input_lines[7])\n",
        "# sample_output.append(output_lines[7])\n",
        "# sample_input.append(input_lines[10])\n",
        "# sample_output.append(output_lines[10])\n",
        "# sample_input.append(input_lines[18])\n",
        "# sample_output.append(output_lines[18])\n",
        "# sample_input.append(input_lines[21])\n",
        "# sample_output.append(output_lines[21])\n",
        "#sample_input.append(\"I love you the cute  Dragon\")\n",
        "#sample_output.append(\"I love you honorable Dragon in the dragonstone .\")\n",
        "# sample_input_paragraphs = []\n",
        "# sample_output_paragraphs = []\n",
        "\n",
        "# paragraph1 = input_lines[6] + \" \" + input_lines[7] + \" \" + input_lines[10]\n",
        "# paragraph2 = input_lines[18] + \" \" + input_lines[21] + \" \" + sample_input[-1]\n",
        "# corrected_paragraph1 = output_lines[6] + \" \" + output_lines[7] + \" \" + output_lines[10]\n",
        "# corrected_paragraph2 = output_lines[18] + \" \" + output_lines[21] + \" \" + sample_output[-1]\n",
        "# sample_input_paragraphs.append(paragraph1)\n",
        "# sample_input_paragraphs.append(paragraph2)\n",
        "# sample_output_paragraphs.append(corrected_paragraph1)\n",
        "# sample_output_paragraphs.append(corrected_paragraph2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z8Y-uSFmF3Q"
      },
      "source": [
        "json_objects = []\n",
        "\n",
        "def get_indices_and_to_json(paragraph, corrected_paragraph):\n",
        "  source_lines = []\n",
        "  corrected_lines = []\n",
        "  start_indices = []\n",
        "  end_indices = []\n",
        "  source_words = []\n",
        "  corrected_words = []\n",
        "  suggestions = []\n",
        "  counts = []\n",
        "  json_object = []\n",
        "  \n",
        "\n",
        "  source_words = paragraph.split()\n",
        "  corrected_words = corrected_paragraph.split()\n",
        "  curr_index = 0\n",
        "  check_sum = 0\n",
        "  i = 0\n",
        "  j = 0\n",
        "  while i < len(source_words) and j < len(corrected_words):\n",
        "    curr_index += len(corrected_words[j]) + 1\n",
        "    if source_words[i] == corrected_words[j]:\n",
        "      i += 1\n",
        "      j += 1\n",
        "    else:      \n",
        "      try:\n",
        "        if j + 1 < len(corrected_words) and corrected_words[j + 1] == source_words[i]:\n",
        "          check_sum += len(corrected_words[j])\n",
        "          start_indices.append(curr_index - check_sum)\n",
        "          end_indices.append(curr_index - check_sum - len(corrected_words[j]) + 2)\n",
        "          suggestions.append(\" \" + corrected_words[j] + \" \")\n",
        "          j += 1\n",
        "          print(check_sum)\n",
        "          print(curr_index)\n",
        "          \n",
        "          # if count not in counts: counts.append(count)\n",
        "        elif i + 1 < len(source_words) and  source_words[i+1] == corrected_words[j]:\n",
        "          check_sum -= len(source_words[i])\n",
        "          start_indices.append(curr_index - len(corrected_words[j]) - check_sum)\n",
        "          end_indices.append(curr_index - len(corrected_words[j]) + len(source_words[i]) - check_sum + 1)\n",
        "          suggestions.append(\"\")\n",
        "          \n",
        "          print(check_sum)\n",
        "          print(curr_index)\n",
        "          i += 1\n",
        "          # if count not in counts: counts.append(count)\n",
        "        else:\n",
        "          check_sum += len(corrected_words[j])-len(source_words[i])\n",
        "          start_indices.append(curr_index - check_sum - len(source_words[i]) - 1)\n",
        "          end_indices.append(curr_index - check_sum - 1)\n",
        "          suggestions.append(corrected_words[j])\n",
        "          \n",
        "          print(check_sum)\n",
        "          print(curr_index)\n",
        "          \n",
        "          i += 1\n",
        "          j += 1\n",
        "          # if count not in counts: counts.append(count)\n",
        "      except:\n",
        "        break\n",
        "  while i < len(source_words):\n",
        "    start_indices.append(curr_index)\n",
        "    end_indices.append(curr_index + len(source_words[i]))\n",
        "    suggestions.append(\"\")\n",
        "    curr_index += len(source_words[i]) + 1\n",
        "    i += 1\n",
        "  curr_str = \"\"\n",
        "  while j < len(corrected_words):\n",
        "    curr_str += \" \" + corrected_words[j]\n",
        "    j += 1\n",
        "  if len(curr_str) > 0:\n",
        "    start_indices.append(len(paragraph))\n",
        "    end_indices.append(len(paragraph) + 1)\n",
        "    suggestions.append(curr_str)\n",
        "  for i in range(len(suggestions)):\n",
        "    temp_dict = OrderedDict()\n",
        "    temp_dict.update({\"start_index\": start_indices[i]})\n",
        "    temp_dict.update({\"end_index\": end_indices[i]})\n",
        "    temp_dict.update({\"suggestion\": suggestions[i]})  \n",
        "    json_object.append(temp_dict)\n",
        "  json_objects.append(json_object)\n",
        "\n",
        "#For sample input test  \n",
        "# for i in range(len(sample_input_paragraphs)):\n",
        "#   get_indices_and_to_json(sample_input_paragraphs[i], sample_output_paragraphs[i])\n",
        "\n",
        "# json_obj = json.dumps(json_objects, indent = 4)\n",
        "# with open(\"sample.json\", \"w\") as outfile:\n",
        "#       outfile.write(json_obj) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzmmRZ8lC0dS",
        "outputId": "b773d7b2-8d72-4df0-af83-85f7a5301395"
      },
      "source": [
        "#inputs through files\n",
        "input_paragraphs = []\n",
        "output_paragraphs = []\n",
        "with open(\"input.txt\") as fp:\n",
        "    input_paragraphs = fp.readlines()\n",
        "with open(\"ABCDN.test.bea19.corr\") as outputfp:\n",
        "  output_paragraphs = outputfp.readlines()\n",
        "\n",
        "#Calling the function and creation of the Json File        \n",
        "for i in range(len(input_paragraphs)):\n",
        "  get_indices_and_to_json(input_paragraphs[i], output_paragraphs[i])\n",
        "\n",
        "json_obj = json.dumps(json_objects, indent = 4)\n",
        "with open(\"output.json\", \"w\") as outfile:\n",
        "      outfile.write(json_obj)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "12\n",
            "1\n",
            "33\n",
            "1\n",
            "39\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFdWvC56H-uC"
      },
      "source": [
        "# sample_input[0][113:116]\n",
        "# sample_input[1][23:33]\n",
        "# sample_input[2][22:25]\n",
        "# sample_input[3][9:10]\n",
        "# sample_input[4][56:58]\n",
        "# sample_input[5][11:15]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}